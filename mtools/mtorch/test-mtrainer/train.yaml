# 也可以使用<<:*注入的方式，但是不方便阅读，就不这样做了
# cur_params 优先级大于 int_method
tag: LT-classifier

dataset:
  defin_path: ./dataset.py
  defin_parm: {dataset: cifar10}
  batch_size: 128
  num_worker: 0
  isdroplast: true
  is_shuffle: true
  defin_sampler: null
  param_sampler: {}


network:
  use_cuda: true
  use_parallel: false
  modules:
    extractors:
      defin_path: ../models/resnet/resnet10_cifar.py
      defin_parm: {use_fc: false, dropout: null}
      cur_params: &cur_params null
      int_method: &int_method kaiming
      optimizers: &optimizers {type: Adam, lr: 0.02, cur_params: *cur_params}
#      schedulers: &schedulers {type: ReduceLROnPlateau, mode: max, factor: 0.1, patience: 10, cur_params: *cur_params}
#      int_method: &int_method normal
#      optimizers: &optimizers {type: SGD, lr: 0.2, momentum: 0.9, weight_decay: 0.0005, cur_params: *cur_params}
      schedulers: &schedulers {type: CosineAnnealingLR, half_cycle: 150, eta_min: 1.0e-6, cur_params: *cur_params}

    classifier:
      defin_path: ../models/DotProductClassifier.py
      defin_parm: {feat_dim: 512, num_classes: 10}
      cur_params: *cur_params
      int_method: *int_method
      optimizers: *optimizers
      schedulers: *schedulers

  criterions:
    focalloss:
      defin_path: ../loss/FocalLoss.py
      defin_parm: {weight: null, gamma: 2, mean: average}
#      cur_params: *cur_params
#      int_method: *int_method
#      optimizers: *optimizers
#      schedulers: *schedulers
      weight: 1


trainer:
  checkpoint_mode: {dire: ./checkpoints, type: key_epoch}
#  checkpoint_mode: {dire: ./checkpoints, type: all_epoch}
  validation_step: 1
  threshold_grad: 1e5
  total_epoches: 5000
  current_epoch: 1


monitor:
  logger: true
  stdstream: true
  tensorboardx: true

